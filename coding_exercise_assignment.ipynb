{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKnkOFjTQSfaosLzS303ep",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weixinluo524/AAI2026/blob/main/coding_exercise_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9VShn6_ez_0",
        "outputId": "bf4344f3-f669-4a13-cc54-901ee0757b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price for a 2000 sq ft house in Downtown: $452,598.71\n",
            "\n",
            "Model Coefficients:\n",
            "location_Downtown: 1402.26\n",
            "location_Rural: 7875.61\n",
            "location_Suburb: -9277.87\n",
            "square_footage: 203.11\n"
          ]
        }
      ],
      "source": [
        "#Part 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1) Load generated dataset (generated from ChatGPT with more than 500+record)\n",
        "df = pd.read_csv(\"housing_price_footage_location.csv\")\n",
        "\n",
        "# 2) Rename data columns to match the code\n",
        "df = df.rename(columns={\"footage\": \"square_footage\"})\n",
        "\n",
        "# Features and target\n",
        "X = df[['square_footage', 'location']]\n",
        "y = df['price']\n",
        "# Preprocessing: One-hot encode the location column\n",
        "preprocessor = ColumnTransformer(\n",
        "transformers=[\n",
        "('location', OneHotEncoder(sparse_output=False), ['location'])\n",
        "], remainder='passthrough')\n",
        "# Create pipeline with preprocessing and model\n",
        "model = Pipeline(steps=[\n",
        "('preprocessor', preprocessor),\n",
        "('regressor', LinearRegression())\n",
        "])\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "# Make prediction for a new house: 2000 sq ft in Downtown\n",
        "new_house = pd.DataFrame({'square_footage': [2000], 'location': ['Downtown']})\n",
        "predicted_price = model.predict(new_house)\n",
        "print(f\"Predicted price for a 2000 sq ft house in Downtown: ${predicted_price[0]:,.2f}\")\n",
        "# Display model coefficients\n",
        "feature_names = (model.named_steps['preprocessor']\n",
        ".named_transformers_['location']\n",
        ".get_feature_names_out(['location'])).tolist() + ['square_footage']\n",
        "coefficients = model.named_steps['regressor'].coef_\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 2\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Load CSV. Acquired from Kaggle. source: https://www.kaggle.com/datasets/blastchar/telco-customer-churn/data\n",
        "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert target to binary\n",
        "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Select relevant features\n",
        "numerical_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "categorical_features = ['gender', 'Partner', 'Dependents', 'InternetService',\n",
        "                        'Contract', 'PaymentMethod']\n",
        "\n",
        "X = df[numerical_features + categorical_features]\n",
        "y = df['Churn']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create and train model\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
        "])\n",
        "\n",
        "# Split and train\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(f\"ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNxW4j084366",
        "outputId": "d0c6a319-7d0e-409c-9819-8c915ae4d1f0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            "ROC-AUC Score: 0.830\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.89      0.87      1033\n",
            "           1       0.65      0.56      0.60       374\n",
            "\n",
            "    accuracy                           0.80      1407\n",
            "   macro avg       0.75      0.72      0.73      1407\n",
            "weighted avg       0.79      0.80      0.80      1407\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[921 112]\n",
            " [166 208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part3\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset. I used the same Dataset from Part 2\n",
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Clean TotalCharges column (it contains blanks)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"TotalCharges\"])\n",
        "\n",
        "# Select numerical features for clustering\n",
        "features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "\n",
        "X = df[features]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Elbow Method (K = 1 to 5)\n",
        "inertia = []\n",
        "K = range(1, 6)\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(K), inertia, marker=\"o\")\n",
        "plt.xlabel(\"Number of Clusters (K)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.savefig(\"elbow_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# Apply K-Means with K=3\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Analyze cluster characteristics\n",
        "cluster_summary = df.groupby(\"cluster\")[features].mean().round(2)\n",
        "\n",
        "print(\"Cluster Characteristics:\")\n",
        "print(cluster_summary)\n",
        "\n",
        "# Example targeted strategies\n",
        "for cluster in range(optimal_k):\n",
        "    print(f\"\\nCluster {cluster} Strategy:\")\n",
        "\n",
        "    if cluster_summary.loc[cluster, \"MonthlyCharges\"] > 70:\n",
        "        print(\"High monthly charges customers: Offer loyalty discounts.\")\n",
        "    elif cluster_summary.loc[cluster, \"tenure\"] > 40:\n",
        "        print(\"Long-tenure customers: Provide VIP retention benefits.\")\n",
        "    else:\n",
        "        print(\"New or low-value customers: Offer onboarding incentives.\")\n",
        "\n",
        "# Save cluster assignments\n",
        "df.to_csv(\"customer_segments.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeZVUvj_Ukj3",
        "outputId": "6ec1f917-0491-4142-9411-9f899fa66da4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Characteristics:\n",
            "         tenure  MonthlyCharges  TotalCharges\n",
            "cluster                                      \n",
            "0         29.62           26.63        815.26\n",
            "1         58.57           89.74       5249.43\n",
            "2         13.26           74.97       1031.88\n",
            "\n",
            "Cluster 0 Strategy:\n",
            "New or low-value customers: Offer onboarding incentives.\n",
            "\n",
            "Cluster 1 Strategy:\n",
            "High monthly charges customers: Offer loyalty discounts.\n",
            "\n",
            "Cluster 2 Strategy:\n",
            "High monthly charges customers: Offer loyalty discounts.\n"
          ]
        }
      ]
    }
  ]
}