{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnY3cO8DzAuGS6cXSvtqCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weixinluo524/AAI2026/blob/main/coding_exercise_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9VShn6_ez_0",
        "outputId": "bf4344f3-f669-4a13-cc54-901ee0757b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted price for a 2000 sq ft house in Downtown: $452,598.71\n",
            "\n",
            "Model Coefficients:\n",
            "location_Downtown: 1402.26\n",
            "location_Rural: 7875.61\n",
            "location_Suburb: -9277.87\n",
            "square_footage: 203.11\n"
          ]
        }
      ],
      "source": [
        "#Part 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1) Load generated dataset (generated from ChatGPT with more than 500+record)\n",
        "df = pd.read_csv(\"housing_price_footage_location.csv\")\n",
        "\n",
        "# 2) Rename data columns to match the code\n",
        "df = df.rename(columns={\"footage\": \"square_footage\"})\n",
        "\n",
        "# Features and target\n",
        "X = df[['square_footage', 'location']]\n",
        "y = df['price']\n",
        "# Preprocessing: One-hot encode the location column\n",
        "preprocessor = ColumnTransformer(\n",
        "transformers=[\n",
        "('location', OneHotEncoder(sparse_output=False), ['location'])\n",
        "], remainder='passthrough')\n",
        "# Create pipeline with preprocessing and model\n",
        "model = Pipeline(steps=[\n",
        "('preprocessor', preprocessor),\n",
        "('regressor', LinearRegression())\n",
        "])\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "# Train model\n",
        "model.fit(X_train, y_train)\n",
        "# Make prediction for a new house: 2000 sq ft in Downtown\n",
        "new_house = pd.DataFrame({'square_footage': [2000], 'location': ['Downtown']})\n",
        "predicted_price = model.predict(new_house)\n",
        "print(f\"Predicted price for a 2000 sq ft house in Downtown: ${predicted_price[0]:,.2f}\")\n",
        "# Display model coefficients\n",
        "feature_names = (model.named_steps['preprocessor']\n",
        ".named_transformers_['location']\n",
        ".get_feature_names_out(['location'])).tolist() + ['square_footage']\n",
        "coefficients = model.named_steps['regressor'].coef_\n",
        "print(\"\\nModel Coefficients:\")\n",
        "for feature, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part 2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load Telco churn dataset\n",
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "\n",
        "# --- Cleaning ---\n",
        "# TotalCharges sometimes has blanks -> coerce to numeric (blanks become NaN)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "\n",
        "# Drop identifier\n",
        "if \"customerID\" in df.columns:\n",
        "    df = df.drop(columns=[\"customerID\"])\n",
        "\n",
        "# Target: Churn Yes/No -> 1/0\n",
        "df[\"Churn\"] = (df[\"Churn\"].astype(str).str.strip().str.lower() == \"yes\").astype(int)\n",
        "\n",
        "# Columns\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "num_cols = [c for c in num_cols if c != \"Churn\"]\n",
        "cat_cols = [c for c in df.columns if c not in num_cols + [\"Churn\"]]\n",
        "\n",
        "# --- Simple imputation ---\n",
        "for c in num_cols:\n",
        "    df[c] = df[c].fillna(df[c].median())\n",
        "\n",
        "for c in cat_cols:\n",
        "    mode_val = df[c].mode(dropna=True)\n",
        "    df[c] = df[c].fillna(mode_val.iloc[0] if not mode_val.empty else \"Unknown\")\n",
        "\n",
        "# Features/target\n",
        "X = df.drop(columns=[\"Churn\"])\n",
        "y = df[\"Churn\"]\n",
        "\n",
        "# --- Preprocessing + model pipeline ---\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model = Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"classifier\", LogisticRegression(max_iter=2000, random_state=42)),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# --- Train/test split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# --- Train ---\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluate ---\n",
        "proba = model.predict_proba(X_test)[:, 1]\n",
        "pred = (proba >= 0.5).astype(int)\n",
        "\n",
        "acc = accuracy_score(y_test, pred)\n",
        "auc = roc_auc_score(y_test, proba)\n",
        "cm = confusion_matrix(y_test, pred)\n",
        "report = classification_report(y_test, pred, digits=3)\n",
        "\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"ROC AUC:  {auc:.3f}\")\n",
        "print(\"Confusion matrix [[TN, FP],[FN, TP]]:\")\n",
        "print(cm)\n",
        "print(\"\\nClassification report:\")\n",
        "print(report)\n",
        "\n",
        "# --- Predict for a new customer (example: \"typical\" customer) ---\n",
        "example = {}\n",
        "for c in num_cols:\n",
        "    example[c] = float(df[c].median())\n",
        "for c in cat_cols:\n",
        "    mode_val = df[c].mode(dropna=True)\n",
        "    example[c] = mode_val.iloc[0] if not mode_val.empty else \"Unknown\"\n",
        "\n",
        "new_customer = pd.DataFrame([example])\n",
        "\n",
        "churn_probability = float(model.predict_proba(new_customer)[0, 1])\n",
        "churn_prediction = int(churn_probability >= 0.5)\n",
        "\n",
        "print(\"\\nNew customer (example) churn probability:\", round(churn_probability, 3))\n",
        "print(\"New customer churn prediction (1=churn, 0=no churn):\", churn_prediction)\n",
        "\n",
        "# --- Coefficients with feature names ---\n",
        "ohe = model.named_steps[\"preprocessor\"].named_transformers_[\"cat\"]\n",
        "cat_feature_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
        "feature_names = num_cols + cat_feature_names\n",
        "\n",
        "coefficients = model.named_steps[\"classifier\"].coef_[0]\n",
        "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefficients})\n",
        "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
        "\n",
        "print(\"\\nTop 10 positive coefficients (more churn):\")\n",
        "print(coef_df.sort_values(\"coef\", ascending=False).head(10)[[\"feature\", \"coef\"]])\n",
        "\n",
        "print(\"\\nTop 10 negative coefficients (less churn):\")\n",
        "print(coef_df.sort_values(\"coef\", ascending=True).head(10)[[\"feature\", \"coef\"]])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNxW4j084366",
        "outputId": "96362db6-f0ca-4f6f-c02a-9017a4843493"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.806\n",
            "ROC AUC:  0.842\n",
            "Confusion matrix [[TN, FP],[FN, TP]]:\n",
            "[[926 109]\n",
            " [165 209]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.849     0.895     0.871      1035\n",
            "           1      0.657     0.559     0.604       374\n",
            "\n",
            "    accuracy                          0.806      1409\n",
            "   macro avg      0.753     0.727     0.738      1409\n",
            "weighted avg      0.798     0.806     0.800      1409\n",
            "\n",
            "\n",
            "New customer (example) churn probability: 0.439\n",
            "New customer churn prediction (1=churn, 0=no churn): 0\n",
            "\n",
            "Top 10 positive coefficients (more churn):\n",
            "                           feature      coef\n",
            "16     InternetService_Fiber optic  0.640185\n",
            "36         Contract_Month-to-month  0.579853\n",
            "3                     TotalCharges  0.516280\n",
            "35             StreamingMovies_Yes  0.204145\n",
            "32                 StreamingTV_Yes  0.203591\n",
            "43  PaymentMethod_Electronic check  0.198382\n",
            "18               OnlineSecurity_No  0.156831\n",
            "27                  TechSupport_No  0.132073\n",
            "14               MultipleLines_Yes  0.106086\n",
            "0                    SeniorCitizen  0.054149\n",
            "\n",
            "Top 10 negative coefficients (less churn):\n",
            "                                 feature      coef\n",
            "1                                 tenure -1.241015\n",
            "38                     Contract_Two year -0.773004\n",
            "15                   InternetService_DSL -0.652640\n",
            "2                         MonthlyCharges -0.596379\n",
            "39                   PaperlessBilling_No -0.343088\n",
            "22      OnlineBackup_No internet service -0.301064\n",
            "25  DeviceProtection_No internet service -0.301064\n",
            "28       TechSupport_No internet service -0.301064\n",
            "31       StreamingTV_No internet service -0.301064\n",
            "34   StreamingMovies_No internet service -0.301064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part3\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset. I used the same Dataset from Part 2\n",
        "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
        "\n",
        "# Clean TotalCharges column (it contains blanks)\n",
        "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"TotalCharges\"])\n",
        "\n",
        "# Select numerical features for clustering\n",
        "features = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "\n",
        "X = df[features]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Elbow Method (K = 1 to 5)\n",
        "inertia = []\n",
        "K = range(1, 6)\n",
        "\n",
        "for k in K:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot elbow curve\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(list(K), inertia, marker=\"o\")\n",
        "plt.xlabel(\"Number of Clusters (K)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.title(\"Elbow Method for Optimal K\")\n",
        "plt.savefig(\"elbow_plot.png\")\n",
        "plt.close()\n",
        "\n",
        "# Apply K-Means with K=3\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df[\"cluster\"] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Analyze cluster characteristics\n",
        "cluster_summary = df.groupby(\"cluster\")[features].mean().round(2)\n",
        "\n",
        "print(\"Cluster Characteristics:\")\n",
        "print(cluster_summary)\n",
        "\n",
        "# Example targeted strategies\n",
        "for cluster in range(optimal_k):\n",
        "    print(f\"\\nCluster {cluster} Strategy:\")\n",
        "\n",
        "    if cluster_summary.loc[cluster, \"MonthlyCharges\"] > 70:\n",
        "        print(\"High monthly charges customers: Offer loyalty discounts.\")\n",
        "    elif cluster_summary.loc[cluster, \"tenure\"] > 40:\n",
        "        print(\"Long-tenure customers: Provide VIP retention benefits.\")\n",
        "    else:\n",
        "        print(\"New or low-value customers: Offer onboarding incentives.\")\n",
        "\n",
        "# Save cluster assignments\n",
        "df.to_csv(\"customer_segments.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeZVUvj_Ukj3",
        "outputId": "6ec1f917-0491-4142-9411-9f899fa66da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Characteristics:\n",
            "         tenure  MonthlyCharges  TotalCharges\n",
            "cluster                                      \n",
            "0         29.62           26.63        815.26\n",
            "1         58.57           89.74       5249.43\n",
            "2         13.26           74.97       1031.88\n",
            "\n",
            "Cluster 0 Strategy:\n",
            "New or low-value customers: Offer onboarding incentives.\n",
            "\n",
            "Cluster 1 Strategy:\n",
            "High monthly charges customers: Offer loyalty discounts.\n",
            "\n",
            "Cluster 2 Strategy:\n",
            "High monthly charges customers: Offer loyalty discounts.\n"
          ]
        }
      ]
    }
  ]
}